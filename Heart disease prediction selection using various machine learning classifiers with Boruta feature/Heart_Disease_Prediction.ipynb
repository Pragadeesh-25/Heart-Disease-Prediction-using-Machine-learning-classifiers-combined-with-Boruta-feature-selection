{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "MJ5SAyswf8SU",
        "3F7hNQpNgHUR",
        "fNOlUHtvgcSw",
        "bw8knzndhVxB",
        "nsQQDYAjlG1C",
        "P600WdKIltLB",
        "bSH6mFuvmYtO",
        "-aH2MZyzmvdc",
        "SLJNkUQenHWj",
        "rLgxXkQmn900",
        "ljIaFThRoORP",
        "4F8FBYSpo6di",
        "eku0wRf2pjay",
        "EEqhOnHqqbsz",
        "5GnE7cJKvtYc",
        "LoP2wd2FrxmE"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## **Heart Disease Prediction**\n",
        "\n"
      ],
      "metadata": {
        "id": "Hom8pZtRf1dJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing the libraries"
      ],
      "metadata": {
        "id": "MJ5SAyswf8SU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import seaborn as sb\n",
        "import numpy as np\n",
        "from scipy import interpolate\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import KFold, StratifiedKFold\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "import xgboost as xgb\n",
        "from boruta import BorutaPy\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import roc_curve, roc_auc_score\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, cohen_kappa_score"
      ],
      "metadata": {
        "id": "2bdXlnELgB6p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing the dataset"
      ],
      "metadata": {
        "id": "3F7hNQpNgHUR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = pd.read_csv('Dataset/heart.csv')\n",
        "dataset.head()"
      ],
      "metadata": {
        "id": "NLOGNKlFgKKm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.isnull().sum()"
      ],
      "metadata": {
        "id": "xrpYi-TkgOsm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = dataset.iloc[:, :-1].values\n",
        "y = dataset.iloc[:, -1].values"
      ],
      "metadata": {
        "id": "qm8T4hvMgRaA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x)\n",
        "print(y)"
      ],
      "metadata": {
        "id": "g71UMozNgTvy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## WITHOUT FEATURE SELECTION"
      ],
      "metadata": {
        "id": "F2ibTWaxgWsc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Random Forest"
      ],
      "metadata": {
        "id": "fNOlUHtvgcSw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create and train the random forest classifier\n",
        "rfc = RandomForestClassifier(n_estimators=100)\n",
        "rfc.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = rfc.predict(X_test)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy-Random forest classifier: %0.4f\" %(accuracy))\n"
      ],
      "metadata": {
        "id": "uKNsXeEVhGcS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Performance metrics"
      ],
      "metadata": {
        "id": "cGQaFAxYgoNt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate precision\n",
        "precision = precision_score(y_test, y_pred)\n",
        "\n",
        "# Calculate recall\n",
        "recall = recall_score(y_test, y_pred)\n",
        "\n",
        "# Calculate F1 score\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "# Calculate Cohen's kappa\n",
        "kappa = cohen_kappa_score(y_test, y_pred)\n",
        "\n",
        "print(\"Accuracy: %0.4f\" % accuracy)\n",
        "print(\"Precision: %0.4f\" % precision)\n",
        "print(\"Recall: %0.4f\" % recall)\n",
        "print(\"F1 Score: %0.4f\" % f1)\n",
        "print(\"Cohen's Kappa: %0.4f\" % kappa)\n"
      ],
      "metadata": {
        "id": "6nxKk2u3gmG0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Confusion Matrix"
      ],
      "metadata": {
        "id": "kb4J0UiHgwXE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The true and predicted labels are stored in y_true and y_pred respectively\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Heatmap of the confusion matrix using Seaborn\n",
        "sb.heatmap(cm, annot=True, cmap=\"Blues\", fmt = 'd')\n",
        "\n",
        "# Add axis labels and a title\n",
        "plt.xlabel(\"Predicted labels\")\n",
        "plt.ylabel(\"True labels\")\n",
        "plt.title(\"Confusion Matrix for Random Forest\")\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "n3fZtJZJgu_7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ROC curve"
      ],
      "metadata": {
        "id": "EMOCh3Lwgz5K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
        "\n",
        "auc = roc_auc_score(y_test, y_pred)\n",
        "\n",
        "# plot ROC curve\n",
        "plt.plot(fpr, tpr, label='Random Forest (AUC = %0.2f)' % auc)\n",
        "plt.plot([0, 1], [0, 1], linestyle='--')  # plot random curve\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "EW3jOpW_g4bl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Decision Tree"
      ],
      "metadata": {
        "id": "bw8knzndhVxB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize an empty list to store the model's performance scores\n",
        "scores_dt = []\n",
        "\n",
        "# Train/test the model once without cross-validation\n",
        "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train the decision tree classifier\n",
        "dt = DecisionTreeClassifier(random_state=42)\n",
        "dt.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate the model's performance on the test set\n",
        "y_pred = dt.predict(X_test)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy-Decision tree: %0.4f\" %(accuracy))"
      ],
      "metadata": {
        "id": "AmSGTWNwhptY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Performance metrics"
      ],
      "metadata": {
        "id": "5lEsYr09hqLc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate precision\n",
        "precision = precision_score(y_test, y_pred)\n",
        "\n",
        "# Calculate recall\n",
        "recall = recall_score(y_test, y_pred)\n",
        "\n",
        "# Calculate F1 score\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "# Calculate Cohen's kappa\n",
        "kappa = cohen_kappa_score(y_test, y_pred)\n",
        "\n",
        "print(\"Accuracy: %0.4f\" % accuracy)\n",
        "print(\"Precision: %0.4f\" % precision)\n",
        "print(\"Recall: %0.4f\" % recall)\n",
        "print(\"F1 Score: %0.4f\" % f1)\n",
        "print(\"Cohen's Kappa: %0.4f\" % kappa)\n"
      ],
      "metadata": {
        "id": "qehdKWEdinvY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Confusion Matrix"
      ],
      "metadata": {
        "id": "grWIfnh8ipcX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The true and predicted labels are stored in y_true and y_pred respectively\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Heatmap of the confusion matrix using Seaborn\n",
        "sb.heatmap(cm, annot=True, cmap=\"Blues\", fmt = 'd')\n",
        "\n",
        "# Add axis labels and a title\n",
        "plt.xlabel(\"Predicted labels\")\n",
        "plt.ylabel(\"True labels\")\n",
        "plt.title(\"Confusion Matrix for Decision Tree\")\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "qpKVFr5Wivrg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ROC curve"
      ],
      "metadata": {
        "id": "3b24ur-ElBkv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
        "\n",
        "auc = roc_auc_score(y_test, y_pred)\n",
        "\n",
        "# plot ROC curve\n",
        "plt.plot(fpr, tpr, label='Decision Tree (AUC = %0.2f)' % auc)\n",
        "plt.plot([0, 1], [0, 1], linestyle='--')  # plot random curve\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve for Decision Tree')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "hEeZBskdlD8P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Logistic Regression"
      ],
      "metadata": {
        "id": "nsQQDYAjlG1C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize an empty list to store the model's performance scores\n",
        "scores_lr = []\n",
        "\n",
        "# # Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train the logistic regression model\n",
        "lr = LogisticRegression(max_iter=5000, random_state=42)\n",
        "lr.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate the model's performance on the test set\n",
        "y_pred = lr.predict(X_test)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy-Logistic regression classifier: %0.4f\" %(accuracy))"
      ],
      "metadata": {
        "id": "_WbjjxA7lMc9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Performance metrics"
      ],
      "metadata": {
        "id": "bHbPPBnmlO_n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score, cohen_kappa_score\n",
        "\n",
        "# Calculate precision\n",
        "precision = precision_score(y_test, y_pred)\n",
        "\n",
        "# Calculate recall\n",
        "recall = recall_score(y_test, y_pred)\n",
        "\n",
        "# Calculate F1 score\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "# Calculate Cohen's kappa\n",
        "kappa = cohen_kappa_score(y_test, y_pred)\n",
        "\n",
        "print(\"Accuracy: %0.4f\" % accuracy)\n",
        "print(\"Precision: %0.4f\" % precision)\n",
        "print(\"Recall: %0.4f\" % recall)\n",
        "print(\"F1 Score: %0.4f\" % f1)\n",
        "print(\"Cohen's Kappa: %0.4f\" % kappa)\n"
      ],
      "metadata": {
        "id": "8TyDaVJwlRya"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Confusion matrix"
      ],
      "metadata": {
        "id": "IH8Uu0LUle1V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Heatmap of the confusion matrix using Seaborn\n",
        "sb.heatmap(cm, annot=True, cmap=\"Blues\", fmt = 'd')\n",
        "\n",
        "# Add axis labels and a title\n",
        "plt.xlabel(\"Predicted labels\")\n",
        "plt.ylabel(\"True labels\")\n",
        "plt.title(\"Confusion Matrix for Logistic Regression\")\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "4GyJxHe7lhs-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ROC Curve"
      ],
      "metadata": {
        "id": "oMTl5nnzligS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
        "\n",
        "auc = roc_auc_score(y_test, y_pred)\n",
        "\n",
        "# plot ROC curve\n",
        "plt.plot(fpr, tpr, label='Random Forest (AUC = %0.2f)' % auc)\n",
        "plt.plot([0, 1], [0, 1], linestyle='--')  # plot random curve\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve for Logistic Regression')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "szWGNcPJllib"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### KNN"
      ],
      "metadata": {
        "id": "P600WdKIltLB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# # Split the data into training and testing sets\n",
        " X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train the k-NN classifier with k=5\n",
        "knn = KNeighborsClassifier(n_neighbors=5)\n",
        "knn.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = knn.predict(X_test)\n",
        "\n",
        "# Compute accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Print the accuracy\n",
        "print(\"Accuracy for k-NN: %0.4f\" % accuracy)\n"
      ],
      "metadata": {
        "id": "SlQGNF7Llsaq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Performance metrics"
      ],
      "metadata": {
        "id": "Uh9LfiCqlxl7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate precision\n",
        "precision = precision_score(y_test, y_pred)\n",
        "\n",
        "# Calculate recall\n",
        "recall = recall_score(y_test, y_pred)\n",
        "\n",
        "# Calculate F1 score\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "# Calculate Cohen's kappa\n",
        "kappa = cohen_kappa_score(y_test, y_pred)\n",
        "\n",
        "print(\"Accuracy: %0.4f\" % accuracy)\n",
        "print(\"Precision: %0.4f\" % precision)\n",
        "print(\"Recall: %0.4f\" % recall)\n",
        "print(\"F1 Score: %0.4f\" % f1)\n",
        "print(\"Cohen's Kappa: %0.4f\" % kappa)\n"
      ],
      "metadata": {
        "id": "euCzVgKClw2P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Confusion matrix"
      ],
      "metadata": {
        "id": "Q1vugHBnmJqK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The true and predicted labels are stored in y_true and y_pred respectively\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Heatmap of the confusion matrix using Seaborn\n",
        "sb.heatmap(cm, annot=True, cmap=\"Blues\", fmt = 'd')\n",
        "\n",
        "# Add axis labels and a title\n",
        "plt.xlabel(\"Predicted labels\")\n",
        "plt.ylabel(\"True labels\")\n",
        "plt.title(\"Confusion Matrix for K - NN\")\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TzwAaPVumKI7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ROC curve"
      ],
      "metadata": {
        "id": "780iJUSWmKly"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
        "\n",
        "auc = roc_auc_score(y_test, y_pred)\n",
        "\n",
        "# plot ROC curve\n",
        "plt.plot(fpr, tpr, label='K - NN (AUC = %0.2f)' % auc)\n",
        "plt.plot([0, 1], [0, 1], linestyle='--')  # plot random curve\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve for k - NN')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "T9x-afVLmLZv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SVM"
      ],
      "metadata": {
        "id": "bSH6mFuvmYtO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "svm_b = SVC(kernel='linear', random_state=42, probability=True)\n",
        "\n",
        "svm_b.fit(X_train, y_train)\n",
        "\n",
        "y_pred = svm_b.predict(X_test)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(\"Accuracy of Logistic Regression with Boruta Feature selection: %0.4f\" % accuracy)"
      ],
      "metadata": {
        "id": "UOIUqlvxmaQy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Performance metrics"
      ],
      "metadata": {
        "id": "4GEUuryVmbBI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate precision\n",
        "precision = precision_score(y_test, y_pred)\n",
        "\n",
        "# Calculate recall\n",
        "recall = recall_score(y_test, y_pred)\n",
        "\n",
        "# Calculate F1 score\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "# Calculate Cohen's kappa\n",
        "kappa = cohen_kappa_score(y_test, y_pred)\n",
        "\n",
        "print(\"Accuracy: %0.4f\" % accuracy)\n",
        "print(\"Precision: %0.4f\" % precision)\n",
        "print(\"Recall: %0.4f\" % recall)\n",
        "print(\"F1 Score: %0.4f\" % f1)\n",
        "print(\"Cohen's Kappa: %0.4f\" % kappa)"
      ],
      "metadata": {
        "id": "toJ2y4_emeO2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Confusion matrix"
      ],
      "metadata": {
        "id": "tbGEBrJnmj2I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The true and predicted labels are stored in y_true and y_pred respectively\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Heatmap of the confusion matrix using Seaborn\n",
        "sb.heatmap(cm, annot=True, cmap=\"Blues\", fmt = 'd')\n",
        "\n",
        "# Add axis labels and a title\n",
        "plt.xlabel(\"Predicted labels\")\n",
        "plt.ylabel(\"True labels\")\n",
        "plt.title(\"Confusion Matrix for SVM\")\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "wMW239AFmn3d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ROC curve"
      ],
      "metadata": {
        "id": "ltSZnX8tmr9w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
        "\n",
        "auc = roc_auc_score(y_test, y_pred)\n",
        "\n",
        "# plot ROC curve\n",
        "plt.plot(fpr, tpr, label='K - NN (AUC = %0.2f)' % auc)\n",
        "plt.plot([0, 1], [0, 1], linestyle='--')  # plot random curve\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve for SVM')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "uCY9Fu4NmuF2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Naive Bayesian"
      ],
      "metadata": {
        "id": "-aH2MZyzmvdc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
        "nb= GaussianNB()\n",
        "nb.fit(X_train, y_train)\n",
        "\n",
        "y_pred = nb.predict(X_test)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(\"Accuracy of Naive - bayesian with Boruta Feature selection: %0.4f\" % accuracy)"
      ],
      "metadata": {
        "id": "_sU5qmC4m1A4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Performance metrics"
      ],
      "metadata": {
        "id": "I4InhU0dm1_Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate precision\n",
        "precision = precision_score(y_test, y_pred)\n",
        "\n",
        "# Calculate recall\n",
        "recall = recall_score(y_test, y_pred)\n",
        "\n",
        "# Calculate F1 score\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "# Calculate Cohen's kappa\n",
        "kappa = cohen_kappa_score(y_test, y_pred)\n",
        "\n",
        "print(\"Accuracy: %0.4f\" % accuracy)\n",
        "print(\"Precision: %0.4f\" % precision)\n",
        "print(\"Recall: %0.4f\" % recall)\n",
        "print(\"F1 Score: %0.4f\" % f1)\n",
        "print(\"Cohen's Kappa: %0.4f\" % kappa)"
      ],
      "metadata": {
        "id": "zQ8d0W2dm5MY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Confusion matrix"
      ],
      "metadata": {
        "id": "ah9FxaZbm5kw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The true and predicted labels are stored in y_true and y_pred respectively\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Heatmap of the confusion matrix using Seaborn\n",
        "sb.heatmap(cm, annot=True, cmap=\"Blues\", fmt = 'd')\n",
        "\n",
        "# Add axis labels and a title\n",
        "plt.xlabel(\"Predicted labels\")\n",
        "plt.ylabel(\"True labels\")\n",
        "plt.title(\"Confusion Matrix for NB\")\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "z3HaENpBm78K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ROC curve"
      ],
      "metadata": {
        "id": "E7QhlThNm8Yv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
        "\n",
        "auc = roc_auc_score(y_test, y_pred)\n",
        "\n",
        "# plot ROC curve\n",
        "plt.plot(fpr, tpr, label='K - NN (AUC = %0.2f)' % auc)\n",
        "plt.plot([0, 1], [0, 1], linestyle='--')  # plot random curve\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve for NB')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "YDp2KFOlm-VZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Voting Ensemble"
      ],
      "metadata": {
        "id": "SLJNkUQenHWj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, VotingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# Initialize the models\n",
        "rf = RandomForestClassifier(n_estimators=50)\n",
        "dt = DecisionTreeClassifier(random_state=42)\n",
        "ada = AdaBoostClassifier(estimator=dt, n_estimators=100)\n",
        "\n",
        "# Fit the models to the entire dataset\n",
        "rf.fit(x, y)\n",
        "dt.fit(x, y)\n",
        "ada.fit(x, y)\n",
        "\n",
        "# Combine the models into a voting classifier\n",
        "ensemble = VotingClassifier(estimators=[('rf', rf), ('ada', ada)], voting='hard')\n",
        "\n",
        "# Fit the ensemble model to the entire dataset\n",
        "ensemble.fit(x, y)\n",
        "\n",
        "# Make predictions on the entire dataset\n",
        "y_pred = ensemble.predict(x)\n",
        "\n",
        "# Calculate the accuracy score\n",
        "score = accuracy_score(y, y_pred)\n",
        "\n",
        "# Print the result\n",
        "print(\"AdaBoost Ensemble accuracy: %0.4f\" % score)\n"
      ],
      "metadata": {
        "id": "YOO6A2mLnLUr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### XGBoost"
      ],
      "metadata": {
        "id": "rLgxXkQmn900"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.30, random_state=42)\n",
        "\n",
        "# Define the XGBoost classifier\n",
        "clf = xgb.XGBClassifier()\n",
        "\n",
        "# Train the classifier\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
      ],
      "metadata": {
        "id": "YVdRq_9UoALR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### AdaBoosting"
      ],
      "metadata": {
        "id": "ljIaFThRoORP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Define the AdaBoost classifier\n",
        "clf = AdaBoostClassifier()\n",
        "\n",
        "# Train the classifier\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
      ],
      "metadata": {
        "id": "0mg0pNGOoRDN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Boruta feature selection"
      ],
      "metadata": {
        "id": "-naMPYy8oSsD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install boruta"
      ],
      "metadata": {
        "id": "_y-J1gLvof5S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the random forest classifier\n",
        "rf = RandomForestClassifier(n_estimators=100, n_jobs=-1)\n",
        "\n",
        "# Define the Boruta feature selection method\n",
        "boruta = BorutaPy(rf, n_estimators='auto', verbose=2)\n",
        "\n",
        "# Perform feature selection\n",
        "boruta.fit(x, y)\n",
        "\n",
        "# Get the selected features\n",
        "selected_features = dataset.columns[:-1][boruta.support_].tolist()[:6]\n",
        "print(\"Selected features:\", selected_features)\n",
        "\n",
        "# Use selected features with your classifier\n",
        "x_selected = dataset[selected_features]\n",
        "\n",
        "# # Split the data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(x_selected, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "NwAVPTPnoY3s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Random forest"
      ],
      "metadata": {
        "id": "4F8FBYSpo6di"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(x_selected, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create and train the random forest classifier\n",
        "rfc = RandomForestClassifier(n_estimators=100)\n",
        "rfc.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = rfc.predict(X_test)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy-Random forest classifier: %0.4f\" %(accuracy))\n"
      ],
      "metadata": {
        "id": "gE4tI1nQo7EZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Performance metrics"
      ],
      "metadata": {
        "id": "83mPzYqRpEYH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate precision\n",
        "precision = precision_score(y_test, y_pred)\n",
        "\n",
        "# Calculate recall\n",
        "recall = recall_score(y_test, y_pred)\n",
        "\n",
        "# Calculate F1 score\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "# Calculate Cohen's kappa\n",
        "kappa = cohen_kappa_score(y_test, y_pred)\n",
        "\n",
        "print(\"Accuracy: %0.4f\" % accuracy)\n",
        "print(\"Precision: %0.4f\" % precision)\n",
        "print(\"Recall: %0.4f\" % recall)\n",
        "print(\"F1 Score: %0.4f\" % f1)\n",
        "print(\"Cohen's Kappa: %0.4f\" % kappa)\n"
      ],
      "metadata": {
        "id": "bT7-hMhJo8Iv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Confusion matrix"
      ],
      "metadata": {
        "id": "iWtkyOkzpSYp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cm = confusion_matrix(y_pred,y_test)\n",
        "\n",
        "# Heatmap of the confusion matrix using Seaborn\n",
        "sb.heatmap(cm, annot=True, cmap=\"Blues\", fmt = 'd')\n",
        "\n",
        "# Add axis labels and a title\n",
        "plt.xlabel(\"Predicted labels\")\n",
        "plt.ylabel(\"True labels\")\n",
        "plt.title(\"Confusion Matrix for Random Forest\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "JjlrARcEpTIR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ROC curve"
      ],
      "metadata": {
        "id": "xU0NhPCSpTa5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
        "\n",
        "auc = roc_auc_score(y_test, y_pred)\n",
        "\n",
        "# plot ROC curve\n",
        "plt.plot(fpr, tpr, label='Random Forest (AUC = %0.2f)' % auc)\n",
        "plt.plot([0, 1], [0, 1], linestyle='--')  # plot random curve\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "U9cft9-qpT1L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Decision tree"
      ],
      "metadata": {
        "id": "eku0wRf2pjay"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize an empty list to store the model's performance scores\n",
        "scores_dt = []\n",
        "\n",
        "# Train/test the model once without cross-validation\n",
        "X_train, X_test, y_train, y_test = train_test_split(x_selected, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train the decision tree classifier\n",
        "dt = DecisionTreeClassifier(random_state=42)\n",
        "dt.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate the model's performance on the test set\n",
        "y_pred = dt.predict(X_test)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy-Random forest classifier: %0.4f\" %(accuracy))\n"
      ],
      "metadata": {
        "id": "0rOVf3JEpl7N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Performance metrics"
      ],
      "metadata": {
        "id": "rzRCQMAxppSm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Calculate precision\n",
        "precision = precision_score(y_test, y_pred)\n",
        "\n",
        "# Calculate recall\n",
        "recall = recall_score(y_test, y_pred)\n",
        "\n",
        "# Calculate F1 score\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "# Calculate Cohen's kappa\n",
        "kappa = cohen_kappa_score(y_test, y_pred)\n",
        "\n",
        "print(\"Accuracy: %0.4f\" % accuracy)\n",
        "print(\"Precision: %0.4f\" % precision)\n",
        "print(\"Recall: %0.4f\" % recall)\n",
        "print(\"F1 Score: %0.4f\" % f1)\n",
        "print(\"Cohen's Kappa: %0.4f\" % kappa)"
      ],
      "metadata": {
        "id": "awjJQyuippyT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Confusion matrix"
      ],
      "metadata": {
        "id": "DIffH24lpsec"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cm = confusion_matrix(y_pred,y_test)\n",
        "\n",
        "# Heatmap of the confusion matrix using Seaborn\n",
        "sb.heatmap(cm, annot=True, cmap=\"Blues\", fmt = 'd')\n",
        "\n",
        "# Add axis labels and a title\n",
        "plt.xlabel(\"Predicted labels\")\n",
        "plt.ylabel(\"True labels\")\n",
        "plt.title(\"Confusion Matrix for Decision Tree\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "1PYyHO1Bps6Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ROC curve"
      ],
      "metadata": {
        "id": "VPXdE2tepvPc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
        "\n",
        "auc = roc_auc_score(y_test, y_pred)\n",
        "\n",
        "# plot ROC curve\n",
        "plt.plot(fpr, tpr, label='Random Forest (AUC = %0.2f)' % auc)\n",
        "plt.plot([0, 1], [0, 1], linestyle='--')  # plot random curve\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Kh2t4Rj-pvlT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "nh-3Om7Dp-LE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize an empty list to store the model's performance scores\n",
        "scores_lr = []\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(x_selected, y, test_size=0.25, random_state=42)\n",
        "\n",
        "# Train the logistic regression model\n",
        "lr = LogisticRegression(max_iter=5000, random_state=42)\n",
        "lr.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate the model's performance on the test set\n",
        "y_pred = lr.predict(X_test)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy-Logisitic regression: %0.4f\" %(accuracy))\n"
      ],
      "metadata": {
        "id": "Dbr0vLIip-iP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "BxDvvcgdqJ-X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Calculate precision\n",
        "precision = precision_score(y_test, y_pred)\n",
        "\n",
        "# Calculate recall\n",
        "recall = recall_score(y_test, y_pred)\n",
        "\n",
        "# Calculate F1 score\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "# Calculate Cohen's kappa\n",
        "kappa = cohen_kappa_score(y_test, y_pred)\n",
        "\n",
        "print(\"Accuracy: %0.4f\" % accuracy)\n",
        "print(\"Precision: %0.4f\" % precision)\n",
        "print(\"Recall: %0.4f\" % recall)\n",
        "print(\"F1 Score: %0.4f\" % f1)\n",
        "print(\"Cohen's Kappa: %0.4f\" % kappa)"
      ],
      "metadata": {
        "id": "x1Q2Pr09qKtd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "cEKUzp3IqV4-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cm = confusion_matrix(y_pred,y_test)\n",
        "\n",
        "# Heatmap of the confusion matrix using Seaborn\n",
        "sb.heatmap(cm, annot=True, cmap=\"Blues\", fmt = 'd')\n",
        "\n",
        "# Add axis labels and a title\n",
        "plt.xlabel(\"Predicted labels\")\n",
        "plt.ylabel(\"True labels\")\n",
        "plt.title(\"Confusion Matrix for Logistic regression\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "PUkLyKhYqVP3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "vtdrkbziqRSR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
        "\n",
        "auc = roc_auc_score(y_test, y_pred)\n",
        "\n",
        "# plot ROC curve\n",
        "plt.plot(fpr, tpr, label='Random Forest (AUC = %0.2f)' % auc)\n",
        "plt.plot([0, 1], [0, 1], linestyle='--')  # plot random curve\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "6xZAu_QiqRmG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### KNN"
      ],
      "metadata": {
        "id": "EEqhOnHqqbsz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(x_selected, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train the k-NN classifier with k=5\n",
        "knn = KNeighborsClassifier(n_neighbors=5)\n",
        "knn.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = knn.predict(X_test)\n",
        "\n",
        "# Compute accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Print the accuracy\n",
        "print(\"Accuracy for k-NN: %0.4f\" % accuracy)"
      ],
      "metadata": {
        "id": "onReLG3zqbCe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Performance metrics"
      ],
      "metadata": {
        "id": "sZXBqFifqo4J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate precision\n",
        "precision = precision_score(y_test, y_pred)\n",
        "\n",
        "# Calculate recall\n",
        "recall = recall_score(y_test, y_pred)\n",
        "\n",
        "# Calculate F1 score\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "# Calculate Cohen's kappa\n",
        "kappa = cohen_kappa_score(y_test, y_pred)\n",
        "\n",
        "print(\"Accuracy: %0.4f\" % accuracy)\n",
        "print(\"Precision: %0.4f\" % precision)\n",
        "print(\"Recall: %0.4f\" % recall)\n",
        "print(\"F1 Score: %0.4f\" % f1)\n",
        "print(\"Cohen's Kappa: %0.4f\" % kappa)\n"
      ],
      "metadata": {
        "id": "vV-JwyHjqhiU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Confusion matrix"
      ],
      "metadata": {
        "id": "JO1UDAzwquqi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cm = confusion_matrix(y_pred,y_test)\n",
        "\n",
        "# Heatmap of the confusion matrix using Seaborn\n",
        "sb.heatmap(cm, annot=True, cmap=\"Blues\", fmt = 'd')\n",
        "\n",
        "# Add axis labels and a title\n",
        "plt.xlabel(\"Predicted labels\")\n",
        "plt.ylabel(\"True labels\")\n",
        "plt.title(\"Confusion Matrix for Logistic regression\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "vPEcamkGqvFi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ROC curve"
      ],
      "metadata": {
        "id": "UbunmBGzqxGt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
        "\n",
        "auc = roc_auc_score(y_test, y_pred)\n",
        "\n",
        "# plot ROC curve\n",
        "plt.plot(fpr, tpr, label='Random Forest (AUC = %0.2f)' % auc)\n",
        "plt.plot([0, 1], [0, 1], linestyle='--')  # plot random curve\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "EA9LfDoaqygR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SVM"
      ],
      "metadata": {
        "id": "zAJKBV4yq0_1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "svm_b = SVC(kernel='linear', random_state=42, probability=True)\n",
        "\n",
        "svm_b.fit(X_train, y_train)\n",
        "\n",
        "y_pred = svm_b.predict(X_test)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(\"Accuracy of Logistic Regression with Boruta Feature selection: %0.4f\" % accuracy)"
      ],
      "metadata": {
        "id": "S9JqOlT7q4Lk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Performance metrics"
      ],
      "metadata": {
        "id": "o5DL_i0drZuc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate precision\n",
        "precision = precision_score(y_test, y_pred)\n",
        "\n",
        "# Calculate recall\n",
        "recall = recall_score(y_test, y_pred)\n",
        "\n",
        "# Calculate F1 score\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "# Calculate Cohen's kappa\n",
        "kappa = cohen_kappa_score(y_test, y_pred)\n",
        "\n",
        "print(\"Accuracy: %0.4f\" % accuracy)\n",
        "print(\"Precision: %0.4f\" % precision)\n",
        "print(\"Recall: %0.4f\" % recall)\n",
        "print(\"F1 Score: %0.4f\" % f1)\n",
        "print(\"Cohen's Kappa: %0.4f\" % kappa)"
      ],
      "metadata": {
        "id": "IG1XbeSpraZp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Confusion matrix"
      ],
      "metadata": {
        "id": "Bw6ytsGira_Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cm = confusion_matrix(y_pred,y_test)\n",
        "\n",
        "# Heatmap of the confusion matrix using Seaborn\n",
        "sb.heatmap(cm, annot=True, cmap=\"Blues\", fmt = 'd')\n",
        "\n",
        "# Add axis labels and a title\n",
        "plt.xlabel(\"Predicted labels\")\n",
        "plt.ylabel(\"True labels\")\n",
        "plt.title(\"Confusion Matrix for SVM\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "bqtyXvx6rbrW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ROC curve"
      ],
      "metadata": {
        "id": "B80pyjEorudf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
        "\n",
        "auc = roc_auc_score(y_test, y_pred)\n",
        "\n",
        "# plot ROC curve\n",
        "plt.plot(fpr, tpr, label='Random Forest (AUC = %0.2f)' % auc)\n",
        "plt.plot([0, 1], [0, 1], linestyle='--')  # plot random curve\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "aLTjnewGrvEx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Logistic Regression"
      ],
      "metadata": {
        "id": "5GnE7cJKvtYc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize an empty list to store the model's performance scores\n",
        "scores_lr = []\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(x_selected, y, test_size=0.25, random_state=42)\n",
        "\n",
        "# Train the logistic regression model\n",
        "lr = LogisticRegression(max_iter=5000, random_state=42)\n",
        "lr.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate the model's performance on the test set\n",
        "y_pred = lr.predict(X_test)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy-Logisitic regression: %0.4f\" %(accuracy))\n"
      ],
      "metadata": {
        "id": "5u8bXYQLwOzL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Performance metrics"
      ],
      "metadata": {
        "id": "tC-uuu3BwV4R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate precision\n",
        "precision = precision_score(y_test, y_pred)\n",
        "\n",
        "# Calculate recall\n",
        "recall = recall_score(y_test, y_pred)\n",
        "\n",
        "# Calculate F1 score\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "# Calculate Cohen's kappa\n",
        "kappa = cohen_kappa_score(y_test, y_pred)\n",
        "\n",
        "print(\"Accuracy: %0.4f\" % accuracy)\n",
        "print(\"Precision: %0.4f\" % precision)\n",
        "print(\"Recall: %0.4f\" % recall)\n",
        "print(\"F1 Score: %0.4f\" % f1)\n",
        "print(\"Cohen's Kappa: %0.4f\" % kappa)"
      ],
      "metadata": {
        "id": "VIQ03cIpwYl5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Confusion matrix"
      ],
      "metadata": {
        "id": "ox2mNCOGwirY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cm = confusion_matrix(y_pred,y_test)\n",
        "\n",
        "# Heatmap of the confusion matrix using Seaborn\n",
        "sb.heatmap(cm, annot=True, cmap=\"Blues\", fmt = 'd')\n",
        "\n",
        "# Add axis labels and a title\n",
        "plt.xlabel(\"Predicted labels\")\n",
        "plt.ylabel(\"True labels\")\n",
        "plt.title(\"Confusion Matrix for Logistic regression\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "DHPZBQL9wfBV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ROC curve"
      ],
      "metadata": {
        "id": "cqls2Enmwlwv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
        "\n",
        "auc = roc_auc_score(y_test, y_pred)\n",
        "\n",
        "# plot ROC curve\n",
        "plt.plot(fpr, tpr, label='Random Forest (AUC = %0.2f)' % auc)\n",
        "plt.plot([0, 1], [0, 1], linestyle='--')  # plot random curve\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "VFCkOvnYwhpW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Naive Bayesian"
      ],
      "metadata": {
        "id": "LoP2wd2FrxmE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nb= GaussianNB()\n",
        "nb.fit(X_train, y_train)\n",
        "\n",
        "y_pred = nb.predict(X_test)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(\"Accuracy of Naive - bayesian with Boruta Feature selection: %0.4f\" % accuracy)"
      ],
      "metadata": {
        "id": "H_ckGmSOr3KK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Performance metrics"
      ],
      "metadata": {
        "id": "UPzjIKner_qY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate precision\n",
        "precision = precision_score(y_test, y_pred)\n",
        "\n",
        "# Calculate recall\n",
        "recall = recall_score(y_test, y_pred)\n",
        "\n",
        "# Calculate F1 score\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "# Calculate Cohen's kappa\n",
        "kappa = cohen_kappa_score(y_test, y_pred)\n",
        "\n",
        "print(\"Accuracy: %0.4f\" % accuracy)\n",
        "print(\"Precision: %0.4f\" % precision)\n",
        "print(\"Recall: %0.4f\" % recall)\n",
        "print(\"F1 Score: %0.4f\" % f1)\n",
        "print(\"Cohen's Kappa: %0.4f\" % kappa)"
      ],
      "metadata": {
        "id": "_imrI3ulr-x8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Confusion matrix"
      ],
      "metadata": {
        "id": "f_Fca9BXsAhO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cm = confusion_matrix(y_pred,y_test)\n",
        "\n",
        "# Heatmap of the confusion matrix using Seaborn\n",
        "sb.heatmap(cm, annot=True, cmap=\"Blues\", fmt = 'd')\n",
        "\n",
        "# Add axis labels and a title\n",
        "plt.xlabel(\"Predicted labels\")\n",
        "plt.ylabel(\"True labels\")\n",
        "plt.title(\"Confusion Matrix for NB\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "g-3Vc31FsBH1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ROC curve"
      ],
      "metadata": {
        "id": "joA8HxjtsF14"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
        "\n",
        "auc = roc_auc_score(y_test, y_pred)\n",
        "\n",
        "# plot ROC curve\n",
        "plt.plot(fpr, tpr, label='Random Forest (AUC = %0.2f)' % auc)\n",
        "plt.plot([0, 1], [0, 1], linestyle='--')  # plot random curve\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "cSNvN5S2sGiI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Voting Ensemble"
      ],
      "metadata": {
        "id": "7iXDUGPjtBJp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, VotingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# Initialize the models\n",
        "rf = RandomForestClassifier(n_estimators=50)\n",
        "dt = DecisionTreeClassifier(random_state=42)\n",
        "ada = AdaBoostClassifier(estimator=dt, n_estimators=100)\n",
        "\n",
        "# Fit the models to the entire dataset\n",
        "rf.fit(x, y)\n",
        "dt.fit(x, y)\n",
        "ada.fit(x, y)\n",
        "\n",
        "# Combine the models into a voting classifier\n",
        "ensemble = VotingClassifier(estimators=[('rf', rf), ('ada', ada)], voting='hard')\n",
        "\n",
        "# Fit the ensemble model to the entire dataset\n",
        "ensemble.fit(x, y)\n",
        "\n",
        "# Make predictions on the entire dataset\n",
        "y_pred = ensemble.predict(x)\n",
        "\n",
        "# Calculate the accuracy score\n",
        "score = accuracy_score(y, y_pred)\n",
        "\n",
        "# Print the result\n",
        "print(\"AdaBoost Ensemble accuracy: %0.4f\" % score)\n"
      ],
      "metadata": {
        "id": "jDaAAKPWtDvB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### XGBoost"
      ],
      "metadata": {
        "id": "AyNhknk4tE6r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.30, random_state=42)\n",
        "\n",
        "# Define the XGBoost classifier\n",
        "clf = xgb.XGBClassifier()\n",
        "\n",
        "# Train the classifier\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
      ],
      "metadata": {
        "id": "vKCGNt4dtHjY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### AdaBoosting"
      ],
      "metadata": {
        "id": "NQHf29h4tRdv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Define the AdaBoost classifier\n",
        "clf = AdaBoostClassifier()\n",
        "\n",
        "# Train the classifier\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
      ],
      "metadata": {
        "id": "IzJ_oFhltUB5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}